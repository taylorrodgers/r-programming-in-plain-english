[["index.html", "R Programming in Plain English Chapter 1 About This Book 1.1 Things You Should Know Before Reading", " R Programming in Plain English Taylor Rodgers 2021-04-03 Chapter 1 About This Book I never liked most programming books. The same with most programming courses. The reason is that many of them assume you already have a programming background. That assumption doesn’t work well with the R programming language. It’s unique because it’s a statistical programming language. That means the people often needing to learn it are researchers, statisticians, and data analysts – not computer engineers. That’s why I wrote this book. I wanted to explain R programming to people who don’t know how to program. I want to strip away all the bloated, technical jargon used in most texts and explain R programming “in plain English.” It’s hard enough to learn statistics. The same for psychology, business, sociology, medicine, economics, marketing, or whatever you were crazy enough to devote the best years of your life to learning. We don’t need the programming language we use to analyze our data to be as hard to learn as the subject itself. 1.1 Things You Should Know Before Reading Since R is used mostly for statistics, you should know some statistics before reading this book. For example, I assume you know what a p-value is. The same for confidence intervals, regression analysis, and R-square. That being said, this book would make a great companion piece to your first statistics class. If your book or professor references code to perform certain calculations, this will help you understand what it’s doing. With that out of the way, let’s begin! "],["whatisr.html", "Chapter 2 What is R Programming? 2.1 Is R the Best Statistical Programming Language? 2.2 Things to Remember", " Chapter 2 What is R Programming? Before getting setup in R, you need to know what R programming is and what’s so special about it. R is a programming language built by statisticians for statistical analysis. It is well-suited towards running advanced analysis, building predictive models, machine learning, and even more routine data management. R is open source. That means it’s free. The people who developed it wanted to make it accessible to anyone. Since then, R has moved beyond its humble beginnings and developed into a full-blown community of developers. Developers within the community contribute to the R language by developing packages. Packages contain functions that allow you to perform certain tasks. What does that mean in plain English? Imagine what it’s like to move into a new apartment. It’s usually empty when you first move in, but it has running water, a refrigerator, and place to stay warm. So it meets the basic criteria for living - food, water, and shelter. That’s similar to what base R provides. It meets the bare necessities to get started with statistical programming. An R package is like the new furniture you bring into the apartment. It’s the new coffee table and couch. It’s the new coat of paint. All of those things that take an empty apartment and changes it to meet your needs. And that’s what’s so great about the R programming language. It has a lot of flexibility. If you find one package confusing or challenging, you can probably find an easier one to perform the same task. Or you can build your own functions instead. The only thing is you have to understand the basics first. One of those basics is objects. We’ll cover this extensively in another chapter, but R is an object-oriented programming language. That means to succeed with it, you have to understand the object types and how they’re used. If that sounds overwhelming, don’t worry. It’s easier than you think. And focusing on these core components will go a long way to helping you succeed in R. As a matter of fact, I’d “guesstimate” that understanding R objects and packages will take care of 80% of your needs with this language. 2.1 Is R the Best Statistical Programming Language? That’s a matter of debate and boy do people debate it. The nice thing about R is that it’s free and open source and has a vibrant community that contributes to it. It’s also meant for statistics. So much of the base functionality is well-suited towards statisticians and researchers alike. The two big competitors to R are SAS and Python. SAS is a statistical programming language built by a for-profit company. It’s the opposite of open source, which means you have to pay money to use it. That’s not necessarily a bad thing though. It means there’s more rigorous quality testing because that’s what people expect from software that costs money. R packages, on the other hand, may not be as rigorously quality checked. At least not those developed by the community and not the original developers. The SAS Institute (the people who make SAS) have a lot of market power. They’ve been around for far longer and have ingrained themselves in academia and pharmaceutical research. Even though R and Python are the preferred choices for most newer companies and younger professionals, SAS has the advantage of being legacy code. You’re probably not familiar with that term if you haven’t ever programmed before. What that means is that even if R and Python were better alternatives to SAS, it would cost an organization a lot of money and time to have its programmers go back and re-write all their automated, enterprise-wide code. Personally, I’m actually a fan of SAS. I took it in my grad program and enjoyed its clean structure. Unlike R, which has so many packages and various ways to do the same things, SAS has the benefit of simplicity and clean documentation. That’s nice when you are already forcing yourself to learn statistics and don’t want to further stress yourself figuring out a programming language. Python is an interesting competitor of R. It’s interesting because it wasn’t built for statistical programming. Like R, it’s open source and that has led to data scientists building packages that make statistical programming possible. Python is probably more popular with data scientists than researchers and statisticians. Since data scientists are often joined at the hip with computer programmers, it naturally lends itself more to that work. I once worked with a company that ran all of its ETL (extract, transform, and load) processes off of Python. Since the data engineers and architects already used Python for that purpose, it wasn’t difficult for them to learn to use it for data science as well. Is Python better than R? I don’t know because I haven’t programmed much in Python. In my opinion, R is easier to learn for people who’ve already programmed in SQL, since it has a more direct syntax. Other people say that Python is easier to learn for programming newbies because it’s written more like the English language. I didn’t find that to be the case, myself. If you want to develop automated, enterprise level solutions, I do think Python is a better choice. Mostly because it makes it easier for computer engineers to work with you. But if your goal is statistical analysis and reproducible research, R is better in my mind. 2.2 Things to Remember R programming is a free and allows for advanced statistical programming R is managed by a community of developers, who contribute to its growth through packages You must understand object types to succeed with R "],["setup.html", "Chapter 3 Getting Setup in R and RStudio 3.1 How to Download R 3.2 Understanding Base R’s User Interface 3.3 Limitations of R Base 3.4 What is RStudio? 3.5 How to Download RStudio 3.6 Understanding RStudio Interface 3.7 Things to Remember", " Chapter 3 Getting Setup in R and RStudio This chapter will tell you how to download R and RStudio. It will also explain the differences between these two tools and how to navigate their user interfaces. If you have already setup these two tools, feel free to skip ahead to the next chapter. However, if you’re still unsure of how to navigate the tools, you may find certain sections useful. 3.1 How to Download R To download R, go to this website: https://www.r-project.org/ You will then have to go through a series of options and screens to download R. Don’t worry. I’ll explain each of them along the way. First, you’ll select the “download R” link in the first paragraph. Second, you’ll select a CRAN mirror. Select the one that’s closest to you. For example, I live in Lawrence, Kansas. That conveniently has a CRAN mirror in my own city. If you live in Melbourne, Australia, you’ll select the mirror hosted by the University of Melbourne. Don’t worry. There’s not much difference to the user in these mirrors. It simply helps optimize your ability to download packages from a nearby source, rather than from some other country in the world. This isn’t a big deal for a small time programmer or researcher, but it’s beneficial for large scale operations to carefully choose their mirror. Third, you’ll select the option for your operating system: That will take you to a page where you can select the latest release: Download and install the latest release. 3.2 Understanding Base R’s User Interface I won’t focus too much on the R interface. We won’t use it much in this book. We’ll be using RStudio (more on that in a bit). However, go ahead and open up R. If you have a Mac, it will have this icon: Once you open it, you should see the R console. The R console is where you type commands. You’ll continue to use the console in RStudio later. Go ahead and input 2*2 to get a feel for it. You can hit Ctrl+Enter on a Windows version and Command+Enter on a Mac OS to run the command. 2*2 ## [1] 4 As you notice, the R console doesn’t allow you to go back and edit previously executed commands. In order to save and edit a script, you’ll need to create a document. A document in this context is basically just a text file that saves the code you want to reference later. Go to the File menu and select New Document. You should have two windows afterwards like the screenshot below: Go ahead and copy and paste this code into the document: install.packages(&quot;faraway&quot;) library(faraway) data(hprice) head(hprice) Highlight different parts of the code and hit Command-Enter or Ctrl-Enter and see how it interacts with the console. (It may ask you to re-select a CRAN mirror. Go ahead and re-select the one you used to download.) Saving scripts this way allows you to modify your code and then re-execute it in the console. We’ll go into more detail about how to input and analyze data later. Go ahead and close R for now. No need to save anything. 3.3 Limitations of R Base The R console in the base version is a simple interface. Sometimes this is nice because you don’t get overwhelmed with all the information displayed in RStudio, which we’ll cover in a second. If you need to run a few calculations and know your data set well, this is a good setup. The downside is that the console can’t display large amounts of data. If you look at the screen shot below, I attempted to review metadata from the US Census Bureau. As you can see, it’s all squished together because the R console can’t cleanly display it. In order to use the R console for further analysis, I’d have to find a different way to view this data I created. That’s where RStudio comes in handy. 3.4 What is RStudio? If you don’t already feel totally confused and overwhelmed with understanding R and R packages – don’t worry. I’m about to make things even more confusing by introducing you to RStudio! RStudio is an IDE (integrated development environment) that allows more interactivity and for you to visually keep track of what you’re doing. In simpler words, it’s a handy user interface for programming in R. It’s far easier to both get started and understand the R programming language by using RStudio. It makes importing data and packages easier. It also makes it easier to manage and visually review what data and packages you have loaded. And lastly, it’s just plain nicer looking. This book will primarily use RStudio for examples. I suggest downloading it to get the best use of my material. 3.5 How to Download RStudio To download RStudio, go to this website: https://rstudio.com/products/rstudio/download/ Scroll down and you’ll see a big blue button to download the latest version of RStudio. You can tell that RStudio was designed for the end-user in mind by how painless it is to download compared to base R. Go ahead and install it once the download finishes. You’ll see an icon like this appear in your applications folder. Go ahead and open it. 3.6 Understanding RStudio Interface The RStudio interface is broken up into four panes. The default pane setting has the following: Source Console Environment, History, and Connections Files, Plots, Package, Help, and Viewer The source pane on the top left is a handy one. This pane displays previously saved or new R scripts you wrote in the past. You may not be able to see this pane yet. Especially if you’ve never opened or saved a script before. To view the source pane, go to the top menu and click File, New File, and then R Script. The source pane can also show loaded data sets as well. If you recall, I said base R had a limitation if you want to review extremely large data sets. This is where RStudio really comes in handy. Down below is the same Census data set that I attempted to view earlier: And here is how it looked in base R: The console pane on the bottom left is more or less the same as the base R console we reviewed earlier. It allows you to enter commands. However, you won’t be able to save those commands as a script unless you write them in the source pane above. That’s similar to what we did with base R and that new document. This pane also has a Terminal and an R Markdown tab (if you have the latter installed). The Terminal allows you to enter commands to interact with your computer. IT professionals use this frequently. You probably won’t. R Markdown may not appear for you yet. I’ll explain what R Markdown in a later chapter, but this tab merely shows the log for producing an R Markdown export. The top right pane includes environment, history, and connections as tabular options. Environment is very handy and it’s something that sets RStudio apart from the base version. It shows objects with assigned names that are saved in your environment. We’ll go into objects extensively in the next chapter. Along with packages, they’re the most important component of R programming. What you need to remember here is that the environment tab in this top right pane tells you what you have saved. The history section is one I don’t use too often, but I could see why some people would find it handy. It tells you what commands you’ve run during your R session. So anything you input in your console will show up here as a record. The connection tab is useful for those who want to connect to a database or data warehouse. If you’re a researcher, you may not use this much. If you work with databases in any capacity, this will make it easier to simply query data directly from the database, as opposed to importing it in via CSV files or spreadsheets. The bottom right pane is a very useful addition provided by RStudio. It contains a separate tab for files, plots, packages, help, and viewer. I’m going to start with the packages tab. If you recall, I said that packages are what makes R such a useful programming language. It allows you to customize and import functions to suit your needs. This is a useful little tab. If you open a previously saved script, you may find out that some functions need a package to execute. This tab can tell you whether you need to install that package or simply need to re-load it. I’ll have a whole chapter dedicated to finding packages, installing packages, and loading packages. Plots is a tab that displays any plots you create using graphical commands. We’ll cover this in more detail in a later chapter. Help is a super helpful tab. You can find the extensive R documentation there that explains many of the functionality of R and how it operates. It also will display information you look up on packages and functions you download. If you ever add a ? before a function, it will display the documentation in the help section. Try adding the following command to the R console and see what happens: ?lm Here’s what it should look like on your screen: Don’t forget about this trick! It helps a lot! Lastly, we have the files and the viewer tab. The files tab displays all the files you can open in RStudio for a given folder. This is helpful because you don’t have to specify a file path when loading files listed here. The viewer tab allows to display non-R related outputs, such as a website or JavaScript graphics. 3.7 Things to Remember R packages contains new functions that allow you to use R for your own specific purposes RStudio is a more user friendly interface "],["objects.html", "Chapter 4 R Objects Types 4.1 Why Do Objects Matter? 4.2 Understanding Object Types Makes It Easier to Transform and Analyze 4.3 The Basic Objects to Remember 4.4 Vectors 4.5 Matrices and Arrays 4.6 Data Frames 4.7 Factors 4.8 Lists 4.9 Functions 4.10 Things to Remember", " Chapter 4 R Objects Types R uses objects to store and interact with data and there are various object types. That probably means little to you now, but understanding these differences will make R programming easier – whatever your R programming goals. In fact, I say it’s better to understand how these objects interact with one another over memorizing every base function and package out there. That’s different from the approach I took to learning R. When I learned R, I went straight to learning the base functions. You know, the cool stuff that does the regression analysis and confidence intervals and whatnot. That didn’t work out well for me. I was coming from a SQL background and thought data worked in a similar way with R. Had I started by learning the objects first, I would’ve saved a lot more time. I would’ve done less data manipulation in SQL or Excel and made simpler, more scalable R code. 4.1 Why Do Objects Matter? Almost everything you program in R does one of the following: Reads an object Modifies an object Produces an object Calls upon a pre-existing object The simple code below utilizes five different object types: confint.lm(happy_model) This code for calculating confidence intervals calls upon a base function, evaluates an existing list, creates several vectors and an array to perform the analysis, and then outputs a matrix. All five are objects. (You can see the function’s script by pasting stats::confint.lm in your console.) Understanding this will help you understand how R can seem to “guess” what it’s supposed to do based on the data inputs. 4.2 Understanding Object Types Makes It Easier to Transform and Analyze Pulling data from one object type is different than pulling data from another. This makes it confusing for people who learned about data through SQL, as opposed to other programming languages. For example, the following code will select most data types in SQL: SELECT Field1, Field2, Field3, Field4 FROM Data_Set That’s different from R. Data selection in R depends on the object type. For example, using the command [6] next to the object name will select a single value from a vector object… money[6] ## [1] 175 But that won’t work for a list object below… happy_model[6] ## $assign ## [1] 0 1 2 To learn how to select, transform, and analyze data in R requires that you learn the underlying structure first. Once you do that, everything else makes more sense. 4.3 The Basic Objects to Remember Down below are the common objects in R: Vectors Matrices / Arrays Data Frames Lists Factors Functions We won’t talk about functions in this chapter since they need their own chapter to explain how they work. 4.4 Vectors Vector is the most basic object within R and there are seven “modes” of vectors: logical, numeric, integer, complex, character, date, and raw. If that seems to be a lot to remember, don’t worry. I’d focus on remembering logical, numeric, and character right now. Those are the ones you’ll use most often. Others we’ll cover as needed. Vectors can only be one mode at a time. What that means in plain English is that R can’t have a word and a number in the same vector. You can use the code below to create and view a logical vector: v1 &lt;- c(TRUE,FALSE,TRUE) v1 ## [1] TRUE FALSE TRUE What this code does is create a vector using the c(input, input) notation. It then assigns the vector the name v1 using the &lt;– notation. (A shortcut to the &lt;- command is Option+“-”.) You build a character vector in the same way, only that you use c(\"input\", \"input\") notation instead: v2 &lt;- c(&quot;Hola&quot;,&quot;Howdy&quot;,&quot;Hello&quot;) v2 ## [1] &quot;Hola&quot; &quot;Howdy&quot; &quot;Hello&quot; And a numeric vector (like the name suggests) looks like this: v3 &lt;- c(1:3) v3 ## [1] 1 2 3 The code above used the c(n1:n2) notation to create a range of values from n1 to n2, where n1 is 1 and n2 is 4. You can also use notations such as c(n1, n2, n3, n4) or like c(n1:n4, n5:n6). Play around with the code below and see what kind numeric vectors you can make! v4 &lt;- c(4:6,1:7) v4 ## [1] 4 5 6 1 2 3 4 5 6 7 v5 &lt;- c(1,5,5,2,1,4) v5 ## [1] 1 5 5 2 1 4 I said before that vectors can only be one “mode” or data type at a time. What that means is that if you attempt to mix numbers or a logical value with a character, it simply changes all values to a character. The code down below takes our previously made vectors, one a numeric and the other a character, and combines them into a single vector. As you can see by the quotation \" \" marks around the output, it’s changed all the numeric values into characters. v6 &lt;- c(v2,v3) v6 ## [1] &quot;Hola&quot; &quot;Howdy&quot; &quot;Hello&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; The vector seems basic and not at all like the data sets you’ll be using. That might make you ask – will I even use vectors? Yes. Yes, you will. The more complex object, data frame, is comprised of individual vectors. (We’ll cover more about the data frame object later). Many functions will also output data in vector form or produce a list composed of vectors. Vectors are also useful as inputs into other functions, as well. If you look below, I used a function from the censusapi package. I create a vector beforehand and then use it as an input for the function below it. variable_list &lt;- c(&quot;B15001_003E&quot;,&quot;B15001_004E&quot;,&quot;B15001_005E&quot;, &quot;B15001_044E&quot;,&quot;B15001_045E&quot;,&quot;B15001_046E&quot;) getCensus(name=&quot;acs/acs5&quot;, vintage=&quot;2018&quot;, vars=c(&quot;NAME&quot;,variable_list), region=&quot;state:*&quot;) You can use vectors in this way on a larger scale. For example, if you write a long script with many functions and references, vectors allow you to create a set of parameters at the beginning. 4.5 Matrices and Arrays Matrices and arrays in R are multi-dimensional vectors. Matrices have multiple rows and columns. Arrays have two or more dimensions. (More on that distinction in a bit). Like their vector counterpart, all matrix / array values must be the same mode or data type – not a mix. That means if you can’t have a numeric value alongside a character value. Here’s an example of a matrix: matrix1 &lt;- matrix(c(2,0,1,3),nrow=2,ncol=2) matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 Why would R programmers want this? It comes back to the R’s use as a statistical programming language. For example, multiple linear regression often has combined variables, which involves multiplying two matrices together. Providing these two object types in R that are solely for numeric values makes this easier. For example, you can multiply these two matrices together with the %*% command and get the same results you would by using matrix algebra: matrix1 &lt;- matrix(c(2,0,1,3),nrow=2,ncol=2) matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 matrix2 &lt;- matrix(c(5,7),nrow=2) matrix2 ## [,1] ## [1,] 5 ## [2,] 7 matrix1 %*% matrix2 #multiplication ## [,1] ## [1,] 17 ## [2,] 21 That’s the same as if you did it yourself by hand. \\[ \\begin{bmatrix} 2 &amp; 1\\\\ 0 &amp; 3 \\\\ \\end{bmatrix} \\begin{bmatrix} 5\\\\ 7\\\\ \\end{bmatrix} = \\begin{bmatrix} 17\\\\ 21\\\\ \\end{bmatrix} \\] Unless you’re building the functions that calculate this, I doubt you’ll use matrices or arrays all that much. However, it’s handy to know what they are and how they can be used. They’re often the output of functions as well. Arrays are more complex than their simple 2-D counterpart. Instead of a single set of rows and columns, you’ll have multiple dimensions added on top. matrix3 &lt;- matrix(c(2,0,1,4,5,2,3,4),nrow=4,ncol=2) matrix4 &lt;- matrix(c(4,3,5,2,1,6,4,5),nrow=4,ncol=2) matrix5 &lt;- matrix(c(1,3,1,2,3,5,6,2),nrow=4,ncol=2) array1 &lt;- array(c(matrix3,matrix4,matrix5), dim=c(4,2,3)) array1 ## , , 1 ## ## [,1] [,2] ## [1,] 2 5 ## [2,] 0 2 ## [3,] 1 3 ## [4,] 4 4 ## ## , , 2 ## ## [,1] [,2] ## [1,] 4 1 ## [2,] 3 6 ## [3,] 5 4 ## [4,] 2 5 ## ## , , 3 ## ## [,1] [,2] ## [1,] 1 3 ## [2,] 3 5 ## [3,] 1 6 ## [4,] 2 2 If the output up above looks like gibberish, don’t worry – most people think it’s confusing when they first see it. That’s because the R user interface doesn’t make it visually intuitive as to how the array operates. Let’s use a picture to visualize this instead. Think of it as if each matrix as a separate entity within the array: What the array does is simply stack them on top of each other: Since arrays with three dimensions are merely stacked matrices, that means each matrix within the array must have the same number of columns and rows. 4.6 Data Frames Data frame is the object type that’s most similar to what you’d find in a SQL database. What I mean by that is that it’s organized and referenced by columns and can have many, many rows. And most importantly, it can contain both numeric and character values! (Earth shattering, I know!) I like to think of a data frame as a way to combine vectors. As a matter of fact, you can build a data frame doing just that. Take this code below and run it. You’ll see that we make individual vectors containing data on James Bond movies1 and we then combine it into a data frame. filmname &lt;- c(&quot;Skyfall&quot;,&quot;Thunderball&quot;,&quot;Goldfinger&quot;, &quot;Spectre&quot;,&quot;Live and Let Die&quot;, &quot;You Only Live Twice&quot;, &quot;The Spy Who Loved Me&quot;,&quot;Casino Royale&quot;, &quot;Moonraker&quot;,&quot;Diamonds Are Forever&quot;, &quot;Quantum of Solace&quot;,&quot;From Russia with Love&quot;, &quot;Die Another Day&quot;,&quot;Goldeneye&quot;, &quot;On Her Majesty&#39;s Secret Service&quot;, &quot;The World is Not Enough&quot;, &quot;For Your Eyes Only&quot;,&quot;Tomorrow Never Dies&quot;, &quot;The Man with the Golden Gun&quot;, &quot;Dr. No&quot;,&quot;Octopussy&quot;, &quot;The Living Daylights&quot;,&quot;A View to a Kill&quot;, &quot;Licence to Kill&quot;) year &lt;- c(&quot;2012&quot;,&quot;1965&quot;,&quot;1964&quot;,&quot;2015&quot;, &quot;1973&quot;,&quot;1967&quot;,&quot;1977&quot;,&quot;2006&quot;, &quot;1979&quot;,&quot;1971&quot;,&quot;2008&quot;,&quot;1963&quot;, &quot;2002&quot;,&quot;1995&quot;,&quot;1969&quot;,&quot;1999&quot;, &quot;1981&quot;,&quot;1997&quot;,&quot;1974&quot;,&quot;1962&quot;, &quot;1983&quot;,&quot;1987&quot;,&quot;1985&quot;,&quot;1989&quot;) actor &lt;- c(&quot;Daniel Craig&quot;,&quot;Sean Connery&quot;, &quot;Sean Connery&quot;,&quot;Daniel Craig&quot;, &quot;Roger Moore&quot;,&quot;Sean Connery&quot;, &quot;Roger Moore&quot;,&quot;Daniel Craig&quot;, &quot;Roger Moore&quot;,&quot;Sean Connery&quot;, &quot;Daniel Craig&quot;,&quot;Sean Connery&quot;, &quot;Pierce Brosnan&quot;,&quot;Pierce Brosnan&quot;, &quot;George Lazenby&quot;,&quot;Pierce Brosnan&quot;, &quot;Roger Moore&quot;,&quot;Pierce Brosnan&quot;, &quot;Roger Moore&quot;,&quot;Sean Connery&quot;, &quot;Roger Moore&quot;,&quot;Timothy Dalton&quot;, &quot;Roger Moore&quot;,&quot;Timothy Dalton&quot;) gross &lt;- c(1108561008,1014941117,912257512, 880669186,825110761,756544419, 692713752,669789482,655872400, 648514469,622246378,576277964, 543639638,529548711,505899782, 491617153,486468881,478946402, 448249281,440759072,426244352, 381088866,321172633,285157191)/1000000 bond &lt;- data.frame(filmname=filmname, year=year, actor=actor, gross=gross) And if you use the $ sign, as we discussed before, you can re-select the individual vectors back out of it. bond$filmname ## [1] &quot;Skyfall&quot; &quot;Thunderball&quot; ## [3] &quot;Goldfinger&quot; &quot;Spectre&quot; ## [5] &quot;Live and Let Die&quot; &quot;You Only Live Twice&quot; ## [7] &quot;The Spy Who Loved Me&quot; &quot;Casino Royale&quot; ## [9] &quot;Moonraker&quot; &quot;Diamonds Are Forever&quot; ## [11] &quot;Quantum of Solace&quot; &quot;From Russia with Love&quot; ## [13] &quot;Die Another Day&quot; &quot;Goldeneye&quot; ## [15] &quot;On Her Majesty&#39;s Secret Service&quot; &quot;The World is Not Enough&quot; ## [17] &quot;For Your Eyes Only&quot; &quot;Tomorrow Never Dies&quot; ## [19] &quot;The Man with the Golden Gun&quot; &quot;Dr. No&quot; ## [21] &quot;Octopussy&quot; &quot;The Living Daylights&quot; ## [23] &quot;A View to a Kill&quot; &quot;Licence to Kill&quot; If you want to select a single column and maintain the data frame object type, you have to use the following code: bond[1] ## filmname ## 1 Skyfall ## 2 Thunderball ## 3 Goldfinger ## 4 Spectre ## 5 Live and Let Die ## 6 You Only Live Twice ## 7 The Spy Who Loved Me ## 8 Casino Royale ## 9 Moonraker ## 10 Diamonds Are Forever ## 11 Quantum of Solace ## 12 From Russia with Love ## 13 Die Another Day ## 14 Goldeneye ## 15 On Her Majesty&#39;s Secret Service ## 16 The World is Not Enough ## 17 For Your Eyes Only ## 18 Tomorrow Never Dies ## 19 The Man with the Golden Gun ## 20 Dr. No ## 21 Octopussy ## 22 The Living Daylights ## 23 A View to a Kill ## 24 Licence to Kill We’ll go into further detail about selecting, transforming, and analyzing data frames later on. The way you go about it depends on whether you want to make efficient code or you want to make “readable” code for other analysts. 4.7 Factors Factors take vectors (or data frame columns) and create categories to group the values. Confused? It’s actually fairly simple. Think back to the data frame we built for the Bond films. If you use the code below, you’ll see the first six rows: head(bond) ## filmname year actor gross ## 1 Skyfall 2012 Daniel Craig 1108.5610 ## 2 Thunderball 1965 Sean Connery 1014.9411 ## 3 Goldfinger 1964 Sean Connery 912.2575 ## 4 Spectre 2015 Daniel Craig 880.6692 ## 5 Live and Let Die 1973 Roger Moore 825.1108 ## 6 You Only Live Twice 1967 Sean Connery 756.5444 Now let’s say you want a short list of the Bond actors. If you’ll notice in the data set, the actor names like “Daniel Craig” and “Sean Connery” are used repeatedly. These are basically ways to group the data frame with a common field name - the actor who played Bond. If we tried to get a list of these actors using the levels() function, it wouldn’t work. levels(bond$actor) ## NULL That’s because it hasn’t been factored yet. This is a real simply fix. Simply use the factor() function and assign it to the field name within the data frame. You can use the code below to do this. bond$actor &lt;- factor(bond$actor) levels(bond$actor) ## [1] &quot;Daniel Craig&quot; &quot;George Lazenby&quot; &quot;Pierce Brosnan&quot; &quot;Roger Moore&quot; ## [5] &quot;Sean Connery&quot; &quot;Timothy Dalton&quot; And this will also show up in the environment tab in the top left. R used to automatically factor character variables for you. However, that functionality was removed in a recent update. You may see factors as a not-so-important object type, but that’s not true. It comes in handy with regression analysis. Especially if your categorical variables are numeric. For example, our Bond data frame may not include the actor name. It could simply have a number between 1 and 6 for the actor - with Sean Connery as 1 and Daniel Craig as 6. That means a regression analysis would’ve analyzed the actor as a continuous variable by default! This also comes up with experiments that analyze the impact of medicine. It’s not uncommon to label one drug as 1 and another drug as 2. That means you’d have to factor those drug codes so that your regression analysis reads them correctly. 4.8 Lists Lists are objects that usually store other objects in a nice bundle. Those objects could be vectors, other lists, data frames, etc. Many of the more complex R base functions produce lists. A common one is produced by the lm() function. Use the code below to build a model with the James Bond data: bondmodel &lt;- lm(gross~actor,data=bond) Now you can see the list this produces in the environment tab. As you can see, there’s a lot in this list. You can also see what’s in the list using the following code: names(bondmodel) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;contrasts&quot; &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; ## [13] &quot;model&quot; This gets to the crux of why it’s important to know when you’re dealing with a list. It changes the way you select components of that list. For example, let’s say you want just the coefficients from a model you had built. You can use the same $ symbol as before. bondmodel$coefficients ## (Intercept) actorGeorge Lazenby actorPierce Brosnan actorRoger Moore ## 820.31651 -314.41673 -309.37854 -269.48336 ## actorSean Connery actorTimothy Dalton ## -95.43409 -487.19349 However, if you want to select a single coefficient, you have to use a number value afterwards: bondmodel$coefficients[4] ## actorRoger Moore ## -269.4834 That’s why it’s important to know if you’re pulling from a list or not. It changes the way that you select key parts of the data. 4.9 Functions Functions are also an object. Most of the time, you’ll be using a built-in function that is in the R base code or in a package you loaded. However, you may find yourself building your own functions, which is handy if you don’t want to search for a pre-existing one or need something unique to your situation. We’ll go into more detail about functions in a later chapter because of their complexity. 4.10 Things to Remember The key to understanding R is understanding objects The object type changes the way you’ll read, transform, and product data (???)↩︎ "],["baserfilter.html", "Chapter 5 How to Filter and Transform Data in Base R 5.1 What Are Operators? 5.2 How to Filter and Transform Data From a Vector 5.3 How to Filter and Transform Data From a Matrix 5.4 How to Filter and Transform Data from Arrays 5.5 How to Filter and Transform Data from a Data Frame 5.6 How to Filter a List 5.7 Things to Remember 5.8 Exercises", " Chapter 5 How to Filter and Transform Data in Base R In the last chapter, I explained the various object types in R. Now we want to learn how to filter and transform those objects. Notice how I didn’t say filter and transform “data”? That’s because the methods you use to handle data in R heavily depend on the object type. Before I explain those methods though, we need to cover operators. 5.1 What Are Operators? If you’re new to programming, then you’re probably not familiar with the term operator. Operators, in plain English, modify or evaluate data. That’s important to data transformation and filtering. There are two types of operators in R: arithmetic and logical. Arithmetic operators cover tasks like addition, subtraction, etc. You know? The basic math stuff. This is useful for data transformation and will be used in several examples later. Here are the common arithmetic operators: label symbol addition + subtraction - multiplication * division / exponent ^ matrix multiplication %*% matrix division %/% Logical operators takes the data and generates a TRUE or FALSE output, based on whether the data meets your requirement. This is more helpful for filtering data than transforming. Here are the common logical operators: label symbol less than &lt; greater than &gt; less than or equal &lt;= greater than or equal &gt;= equal == does not equal != and &amp; or | in %in% Don’t worry if you’re unsure of how to use these just yet. You’ll see examples for these in the next few sections. This is just for your easy reference. 5.2 How to Filter and Transform Data From a Vector Vectors are the easiest object type to filter. Same with transforming the data within them. If you want to reference or view the entire vector, you simply enter the name you assigned the object: v5 &lt;- c(1,5,5,2,1,4) v5 ## [1] 1 5 5 2 1 4 (Remember: the &lt;- command allows you to name any object. You can use Option+“-” as a short-cut for &lt;-.) You also can select a single entry from a vector using the [n] notation: v5 &lt;- c(1,5,5,2,1,4) v5[3] ## [1] 5 As you can see, the script above selected the third value from the vector. You can select a range of entries by using the [n:n] notation. v5 &lt;- c(1,5,5,2,1,4) v5[3:4] ## [1] 5 2 And, as we’ve seen before, you can create a new vector by referencing old vectors! v2 &lt;- c(&quot;Hola&quot;,&quot;Howdy&quot;,&quot;Hello&quot;) v7 &lt;- c(2:4) v8 &lt;- c(v2,v7) v8 ## [1] &quot;Hola&quot; &quot;Howdy&quot; &quot;Hello&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; You can also use other base R functions to filter data. For example, you may want to see the minimum or maximum value in a vector. You can use the max() and min() command to do so. v5 ## [1] 1 5 5 2 1 4 max(v5) # Max value ## [1] 5 min(v5) # Min value ## [1] 1 And you can use logical operators as well. In the example below, I use the &gt;= and &amp; operators to filter values: v5 &gt;= 2 # Values greater than 2 ## [1] FALSE TRUE TRUE TRUE FALSE TRUE v5 &gt;= 3 &amp; v5 &lt;= 5 # Values between 3 and 5 ## [1] FALSE TRUE TRUE FALSE FALSE TRUE We can also use the | operator to find values that meet a criteria. For example, I filter the vector below to “Hola” and “Howdy.” v2 ## [1] &quot;Hola&quot; &quot;Howdy&quot; &quot;Hello&quot; v2 == &quot;Hola&quot; | v2 == &quot;Howdy&quot; ## [1] TRUE TRUE FALSE You probably noticed that these logical operators only return a TRUE or FALSE statement. That makes sense since it is a logical argument that’s evaluated. However, we may want to see the actual values that meet the argument. This isn’t important in an example like this, but it does come up later on for more complex objects. To show the actual values where the logical argument is true, you use the object_name[argument] notation. In the next few examples, I filter the vectors down to values that meet the arguments used in the last few examples: v5[v5&gt;=2] ## [1] 5 5 2 4 v5[v5 &gt;= 3 &amp; v5 &lt;= 5] ## [1] 5 5 4 v2[v2 == &quot;Hola&quot; | v2 == &quot;Howdy&quot;] ## [1] &quot;Hola&quot; &quot;Howdy&quot; In the examples above, I simply took the logical argument and plugged it into the brackets. You can also change data easily when it comes to numeric vectors. For example, down below is a vector of box office revenue for James Bond films. Copy and paste this script into your R console and execute: gross &lt;- c(1108561008,1014941117,912257512,880669186, 825110761,756544419,692713752,669789482, 655872400,648514469,622246378,576277964, 543639638,529548711,505899782,491617153, 486468881,478946402,448249281,440759072, 426244352,381088866,321172633,285157191) gross As you can see, the values are very large. To make our analysis easier, we can use an arithmetic operator I showed earlier. In this scenario, I want to make the values smaller. So I’m going to divide it using the / operator. gross/1000000 You can also calculate individual values this way too. gross[4] ## [1] 880669186 gross[4]/100000 ## [1] 8806.692 And you can re-assign the value to a particular part of a vector using the methods we described above and the &lt;- notation. For example, we can see below how we re-assign values based on the location. v8 &lt;- c(1,5,5,2,1,4) # Creates the original vector v8[6] &lt;- 8 # Replaces the sixth value with an 8 v8[1:3] &lt;- c(4,3,1) # Replaces the first three values v8 ## [1] 4 3 1 2 1 8 5.3 How to Filter and Transform Data From a Matrix Filtering the data within a matrix is both similar and different than a vector. It’s similar because we can use the [n] notation to select a single entry. We had done this before with a vector: v5[2] ## [1] 5 You can do the same for a matrix. If you run the code below, you’ll re-create and view the matrix we used in the last chapter: matrix1 &lt;- matrix(c(2,0,1,3),nrow=2,ncol=2) matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 And here you’ll select the fourth value from that matrix using the [4] command: matrix1[4] ## [1] 3 Now that isn’t very practical for a matrix. You may need to select a value from a specific row or column instead. This is where matrices are different from a vector. You’ll want to use the [r,c] command to determine which values you want. In the example below, I select the second row and first column of the matrix. matrix1[2,1] ## [1] 0 We can make this easier on ourselves. Instead of specifying row or column numbers, we can give them names. That way, we can use the [row_name,column_name] notation to select data from a matrix. Down below, I give our previously created matrix row and column names. colnames(matrix1) &lt;- c(&quot;Col1&quot;,&quot;Col2&quot;) rownames(matrix1) &lt;- c(&quot;Row1&quot;,&quot;Row2&quot;) matrix1[&quot;Row2&quot;,&quot;Col1&quot;] ## [1] 0 We can also apply vector filtering methods to matrices. For example, I want to see what values are greater than 0. matrix1 &gt; 0 # Returns true or false ## Col1 Col2 ## Row1 TRUE TRUE ## Row2 FALSE TRUE Funny enough though, you can’t return the actual values that meet this criteria in a matrix form. It’ll turn into a vector. That’s because the output may not have the same number of columns and rows as the original matrix. So R assumes it’ll need a one-dimensional object output. matrix1[matrix1 &gt; 0] ## [1] 2 1 3 You can use the same techniques we outlined before with the vectors to transform the data within a matrix. Copy and paste the codes below to your R console and see the results. Feel free to play around with the inputs to see what happens. matrix1 &lt;- matrix(c(2,0,1,3),nrow=2,ncol=2) matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 matrix1[3] &lt;- 5 matrix1 ## [,1] [,2] ## [1,] 2 5 ## [2,] 0 3 matrix1[,2] &lt;- 2 matrix1 ## [,1] [,2] ## [1,] 2 2 ## [2,] 0 2 matrix1[2,2] &lt;- 0 matrix1 ## [,1] [,2] ## [1,] 2 2 ## [2,] 0 0 Like the vectors, you can transform the data within the matrix using the arithmetic operators we discussed earlier. matrix1 ## [,1] [,2] ## [1,] 2 2 ## [2,] 0 0 matrix1 + 2 ## [,1] [,2] ## [1,] 4 4 ## [2,] 2 2 matrix1 - 4 ## [,1] [,2] ## [1,] -2 -2 ## [2,] -4 -4 matrix1 ^ 3 ## [,1] [,2] ## [1,] 8 8 ## [2,] 0 0 matrix1 * 5 ## [,1] [,2] ## [1,] 10 10 ## [2,] 0 0 You can also use these operators to combine matrices. We’ll need a few matrices to illustrate these examples though. Take the code I have below and execute it in your console, if you want to follow along with my examples. matrix1 &lt;- matrix(c(2,0,1,3),nrow=2,ncol=2) matrix1 matrix2 &lt;- matrix(c(5,7),nrow=2) matrix2 matrix6 &lt;- matrix(c(4,3,1,3),nrow=2,ncol=2) matrix6 It’s important to remember the dimensions of your matrices. Attempting to use addition on two matrices without the same dimensions won’t work. Matrix 1 and 2 do not have the same dimensions, so it will return an error: matrix1 + matrix2 ## Error in matrix1 + matrix2: non-conformable arrays However, Matrix 1 and Matrix 6 do have the same dimensions and will execute: matrix1 + matrix6 ## [,1] [,2] ## [1,] 6 2 ## [2,] 3 6 Multiplying two matrices together can be misleading. For example, using the simple * operator will merely multiply the corresponding values in two matrices with the same dimensions. Confused? Look at the two matrices below and then look at the output: matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 matrix6 ## [,1] [,2] ## [1,] 4 1 ## [2,] 3 3 matrix1 * matrix6 ## [,1] [,2] ## [1,] 8 1 ## [2,] 0 9 Entry [1,1] of the first matrix is 2. Entry [1,1] of the second matrix is 4. 2 x 4 = 8. That shows us that the multiplication used here is not true matrix multiplication. If you attempt to use the same * operator for Matrix 1 and Matrix 2 though, you will get an error: matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 matrix2 ## [,1] ## [1,] 5 ## [2,] 7 matrix1 * matrix2 ## Error in matrix1 * matrix2: non-conformable arrays That’s because these two matrices do not share the same dimensions. However, we can generate a single matrix from these two matrices using matrix algebra. To do so, we use the %*% operator. matrix7 &lt;- matrix1 %*% matrix2 matrix7 ## [,1] ## [1,] 17 ## [2,] 21 You can also divide a matrix with another using the %/% operator: matrix7 %/% matrix2 ## [,1] ## [1,] 3 ## [2,] 3 Just remember the difference in how a matrix will interact with the *, %*%, /, and %/% operators. 5.4 How to Filter and Transform Data from Arrays Selecting data from arrays is similar to what we did before. You can select an individual entry using the [n] command. If you look down below, we re-create the array we used in the last chapter. Copy and paste this code into your R console. matrix3 &lt;- matrix(c(2,0,1,4,5,2,3,4),nrow=4,ncol=2) matrix4 &lt;- matrix(c(4,3,5,2,1,6,4,5),nrow=4,ncol=2) matrix5 &lt;- matrix(c(1,3,1,2,3,5,6,2),nrow=4,ncol=2) array1 &lt;- array(c(matrix3,matrix4,matrix5), dim=c(4,2,3)) array1 This script will create three separate matrices, like you see below: And then stacks them into an array: You can then select the first and twenty-second entry with the scripts below. array1[1] ## [1] 2 array1[22] ## [1] 5 To help you visualize this, I highlighted the fifth and twenty second values from the array in the illustration below: With arrays, selecting particular columns or rows gets difficult because arrays can have multiple dimensions. That introduces the [r,c,d] notation. Down below, we select the entire second row of every matrix in our array: array1[2,,] ## [,1] [,2] [,3] ## [1,] 0 3 3 ## [2,] 2 6 5 You may have noticed that this “flipped” the direction. R isn’t trying to confuse you. It’s merely displaying the previous, individual matrix rows as columns. So column 1 shows the results from matrix 1 in the previous array. Keep this in mind as you interact with arrays. The output may not always be intuitive. Down below is an illustration of how R processes this command. First, R finds the second row for each level of the array… And R then pivots and places those rows into a new array, with each column representing the level of the array… Just like rows, we can also the second column of every matrix: array1[,2,] ## [,1] [,2] [,3] ## [1,] 5 1 3 ## [2,] 2 6 5 ## [3,] 3 4 6 ## [4,] 4 5 2 Down below is an illustration of how R processes this command. R takes the second column from each level of the array and outputs it. Each column of the output represents the level of the array. We can also select every entry in the third matrix of our array: array1[,,3] ## [,1] [,2] ## [1,] 1 3 ## [2,] 3 5 ## [3,] 1 6 ## [4,] 2 2 We can even get a specific entry by selecting the second row, second column of the third matrix in our array: array1[2,2,3] ## [1] 5 You can transform arrays in the same way as the other objects. Down below are some examples of how we can use those same techniques. Copy and paste the code below to your own computer to get an idea of how this works. array1 #Changes the 2nd value of the entire array to a 2 array1[2] &lt;- 2 array1 #Changes the 2nd column of each matrix to a 2 array1[,2,] &lt;- 2 array1 #Changes the 2nd row, 1st column of the 3rd array to 0 array1[2,1,3] &lt;- 0 array1 #Divided the 3rd matrix only by 3 array1[,,3] &lt;- array1[,,3] / 3 array1 5.5 How to Filter and Transform Data from a Data Frame There’s two approaches you can take to selecting data from a data frame. There’s the “classic” approach, which I’ll show you in this section, and then there’s the data plyer approach. The classic approach uses R base to interact with data frames. The data plyer approach uses a package called dplyr to transform the data. The dplyr syntax is far more readable, which is handy for really long scripts. I personally recommend the data plyer approach and will detail it in a chapter called How to Select and Transform Data Using the dplyr Package. If you don’t want to confuse yourself by learning two different methods, feel free to skip this section and go to the chapter on dplyr. (Will be available in future versions). This section will show the classical approach. Down below is a script to load the James Bond data frame from the last chapter: bond &lt;- read.csv(&quot;https://raw.githubusercontent.com/taylorrodgers/bond/main/bond.csv&quot;) As you can see, a data frame is built using smaller vectors. This gives you a clue to how to select data. For example, you can re-select individual vectors back out using the $ notation: bond$filmname (Note: You’ll need to run the scripts from this section on your own console. The output cannot fit cleanly on this pdf file.) You can also produce a vector using the [,c] notation. What this means is you’re ignoring the row and selecting a column number. We generate the same result as our last section with this method. bond[,1] If you use the [n] notation, you’ll select the same column as before, but you’re keeping it in a data frame structure. bond[1] As you may have noticed, the [n] notation in this context works differently than other object types. For data frames, [n] selects the nth column and NOT the nth data entry. You can use the [n:n] or the [,n:n] notation to select multiple columns. Both will be presented as a data frame. bond[1:3] bond[,1:3] To select an individual or range of rows, you use the same [r,c] notation as before: bond[1:3,] # Selects first three rows ## filmname year actor gross ## 1 Skyfall 2012 Daniel Craig 1108.5610 ## 2 Thunderball 1965 Sean Connery 1014.9411 ## 3 Goldfinger 1964 Sean Connery 912.2575 You can also exclude rows or columns using the negative - sign before the row or column numbers: bond[-1:-20,] # Excludes rows 1 through 20 ## filmname year actor gross ## 21 Octopussy 1983 Roger Moore 426.2444 ## 22 The Living Daylights 1987 Timothy Dalton 381.0889 ## 23 A View to a Kill 1985 Roger Moore 321.1726 ## 24 Licence to Kill 1989 Timothy Dalton 285.1572 bond[3,-4] # Row 3, excluding the 4th column ## filmname year actor ## 3 Goldfinger 1964 Sean Connery Just like the other object types, you can use logical and arithmetic operators, which makes it easy to filter to what you need. Note: this is where things start to get complicated with data frame filtering and why I suggest the dplyr package. Lets say we want to filter by year. We want only Bond films made after 1990. First, we’ll generate our TRUE / FALSE output. Go ahead and take the script below and run it in your own console: bond[&quot;year&quot;]&gt;=1990 Now, you’ll notice that I intentionally kept this as a data frame object type. Had I used the bond$year notation, it would’ve turned it into a vector. This would’ve made further filtering later more difficult. Next, we need to plug this into another script: bond[bond[&quot;year&quot;]&gt;=1990] ## [1] &quot;Skyfall&quot; &quot;Spectre&quot; ## [3] &quot;Casino Royale&quot; &quot;Quantum of Solace&quot; ## [5] &quot;Die Another Day&quot; &quot;Goldeneye&quot; ## [7] &quot;The World is Not Enough&quot; &quot;Tomorrow Never Dies&quot; ## [9] &quot;2012&quot; &quot;2015&quot; ## [11] &quot;2006&quot; &quot;2008&quot; ## [13] &quot;2002&quot; &quot;1995&quot; ## [15] &quot;1999&quot; &quot;1997&quot; ## [17] &quot;Daniel Craig&quot; &quot;Daniel Craig&quot; ## [19] &quot;Daniel Craig&quot; &quot;Daniel Craig&quot; ## [21] &quot;Pierce Brosnan&quot; &quot;Pierce Brosnan&quot; ## [23] &quot;Pierce Brosnan&quot; &quot;Pierce Brosnan&quot; ## [25] &quot;1108.5610&quot; &quot; 880.6692&quot; ## [27] &quot; 669.7895&quot; &quot; 622.2464&quot; ## [29] &quot; 543.6396&quot; &quot; 529.5487&quot; ## [31] &quot; 491.6172&quot; &quot; 478.9464&quot; If you notice though, this doesn’t cleanly give us the information we need. We need to make sure we preserve the columns. We can do this by simply adding a comma and / or specifying the column numbers: bond[bond[&quot;year&quot;]&gt;=1990,] # Includes all columns ## filmname year actor gross ## 1 Skyfall 2012 Daniel Craig 1108.5610 ## 4 Spectre 2015 Daniel Craig 880.6692 ## 8 Casino Royale 2006 Daniel Craig 669.7895 ## 11 Quantum of Solace 2008 Daniel Craig 622.2464 ## 13 Die Another Day 2002 Pierce Brosnan 543.6396 ## 14 Goldeneye 1995 Pierce Brosnan 529.5487 ## 16 The World is Not Enough 1999 Pierce Brosnan 491.6172 ## 18 Tomorrow Never Dies 1997 Pierce Brosnan 478.9464 bond[bond[&quot;year&quot;]&gt;=1990,1:3] # Columns 1 through 3 ## filmname year actor ## 1 Skyfall 2012 Daniel Craig ## 4 Spectre 2015 Daniel Craig ## 8 Casino Royale 2006 Daniel Craig ## 11 Quantum of Solace 2008 Daniel Craig ## 13 Die Another Day 2002 Pierce Brosnan ## 14 Goldeneye 1995 Pierce Brosnan ## 16 The World is Not Enough 1999 Pierce Brosnan ## 18 Tomorrow Never Dies 1997 Pierce Brosnan 5.6 How to Filter a List Unlike the other object types, I won’t go into detail about transforming a list. The reason is that lists are usually reserved as an output of various functions. Or they’re a handy way of bunching other objects together. If you wanted to transform an object within a list, you’d probably transform that object directly. Filtering a list is a useful skill to have though. The script below creates a model using our James Bond data. That creates a list of the various calculations in a regression analysis. The names() function then shows you all the objects contained within the list: bondmodel &lt;- lm(gross ~ actor,data=bond) names(bondmodel) (Note: You’ll need to run the scripts from this section on your own console. The output cannot fit cleanly on this pdf file.) We can select any of these objects within the list with the $, [\"object_name\"], or [n] notations: bondmodel$coefficients bondmodel[&quot;coefficients&quot;] bondmodel[1] Now here’s where things get tricky. Let’s say we want to filter down to a smaller value within the objects of the list. That changes depending on those object types. Confused? It’s better if we go with a simpler example than the list generated by the lm() function. Down below, I create a list using some of the other objects we made in this lesson: v1 &lt;- c(TRUE,FALSE,TRUE) v2 &lt;- c(&quot;Hola&quot;,&quot;Howdy&quot;,&quot;Hello&quot;) v3 &lt;- c(1:3) list1 &lt;- list(vector1=v1, vector2=v2, vector3=v3, matrix1=matrix1, array1=array1, bond=bond) I can select any one of those objects from the list using the $ notation: list1$vector1 ## [1] TRUE FALSE TRUE list1$matrix1 ## [,1] [,2] ## [1,] 2 1 ## [2,] 0 3 Now let’s say I want to select a specific data point from the list. Let’s say I want to know the Bond actors. I know that information was stored within a data frame within the list. To pull that data, I use a combination of filtering techniques. First, I have to pull the data frame from the list. I do that with the $ notation. Then, we treat the object type as a normal data frame. Here’s what I mean: list1$bond[3] list1$bond$actor list1$bond[&quot;actor&quot;] I do the same with the other object types here: list1$vector1[3] ## [1] TRUE list1$vector3[v3&gt;=2] ## [1] 2 3 list1$array1[,2,] ## [,1] [,2] [,3] ## [1,] 2 2 0.6666667 ## [2,] 2 2 0.6666667 ## [3,] 2 2 0.6666667 ## [4,] 2 2 0.6666667 5.7 Things to Remember How you filter and transform data depends upon the object type 5.8 Exercises Try to see if you can complete the following exercises. Answers are in the back of the book! Filter the following vector to values greater than 2. Display the actual number (not TRUE / FALSE). q1 &lt;- seq(1,20,2) Filter the following vector to values between 19 and 20, but only for the first three entries that meet that criteria. (Hint: add [n:n] for the range of values after you determine which values meet that criteria) q2 &lt;- round(rnorm(20,32,7),0) Multiple the following matrices together. q3_1 &lt;- matrix(round(seq(1,40,3.27),0),3) q3_2 &lt;- matrix(seq(1,8,1),4) Subtract 41 from every entry in the second column of the following matrix. Replace the column with those new values. q4 &lt;- matrix(seq(1,120,4),10,3) Select the second row from each matrix in the following array. Subtract 5 from those rows. q5 &lt;- array(data=c(matrix(seq(1,15,1),5,3), matrix(seq(4,60,4),5,3), matrix(seq(2,30,2),5,3)), dim=c(5,3,3)) Filter the James Bond data frame to only films starring Roger Moore. bond Filter the James Bond data frame to films starring Sean Connery made after 1966. bond "],["dplyr.html", "Chapter 6 How to Filter and Transform Data with the Dplyr Package 6.1 Why is dplyr So Popular? 6.2 It’s Still Worth Learning Base R 6.3 The dplyr Syntax 6.4 Understand the Difference Between Selecting and Filtering 6.5 How to Select and Mutate a Data Frame with dplyr in R 6.6 How to Filter a Data Frame with dplyr in R 6.7 How to Summarize and Group Data with dplyr in R 6.8 Things to Remember", " Chapter 6 How to Filter and Transform Data with the Dplyr Package In the last chapter, I showed you how to use R base to filter and transform data. Personally, I still think this is the best way to manage data in R. However, there’s another popular package for data filtering and transformation – the dplyr package. The dplyr package (pronounced like “data plier”) was developed by Hadley Wickham to allow more intuitive data transformation. It falls under the tidyverse packages, which includes other popular R packages created by Mr. Wickham. 6.1 Why is dplyr So Popular? dplyr is popular for its intuitive syntax for filtering and transforming data frames. If your programming background is with SQL, you’ll find it an easier transition to make. dplyr is also highly readable compared to base R. That’s where I see the most value in it. You can send it over to another programmer and it’ll be easier for them to read what you’re doing with the data. 6.2 It’s Still Worth Learning Base R dplyr’s strengths are mostly limited to data frames, whereas base R can work with vectors, matrices, arrays, and lists. That makes it still worthwhile to study base R. This isn’t a knock against dplyr. Much of the work you’ll do requires a data frame and most R functions work with data frames fairly easily. But writing your own functions should be done with base R. 6.3 The dplyr Syntax If you recall, filtering a data frame in base R looks like this: #If needed, you can reload the Bond data set with this script bond &lt;- read.csv(&quot;https://raw.githubusercontent.com/taylorrodgers/bond/main/bond.csv&quot;) bond[bond[&quot;year&quot;]&gt;=1990,1:3] That’s different in dplyr, which looks like this: bond %&gt;% select(filmname,year,actor) %&gt;% filter(year&gt;=1990) You can literally think of the dplyr syntax as a set of instructions to read one-by-one: Hey data set named “Bond”… bond %&gt;% Tell me the film name, year released, and actor name for… select(filmname,year,actor) %&gt;% James Bond films made after 1990 filter(year&gt;=1990) That’s a lot easier to understand than normal base R, ain’t it? 6.4 Understand the Difference Between Selecting and Filtering With dplyr, it’s important to remember the difference between selecting and filtering. Selecting uses the select() function and reduces the columns to those you specify: In addition to select(), there’s also mutate() and transmute(), which serve similar purposes. We’ll cover those two functions in the next section. Filtering uses the filter() function and reduces the rows to those you specify. 6.5 How to Select and Mutate a Data Frame with dplyr in R In dplyr, you can select columns using the select() function: bond %&gt;% select(actor,filmname,gross) Executing the code above will only select the columns actor, filmname, and gross. Sometimes you’ll need to transform or alter the data. That’s where mutate() comes in handy. mutate() will allow you to create new fields that alter existing ones. Confused? Execute the script below to see: bond %&gt;% mutate(gross_millions=gross*1000000) The mutate() function added a new column to the end called gross_millions with our new calculation. The one drawback to mutate() is that it allow you to select specified columns. Rather than add another %&gt;% select() to your code, you can use the transmute() function. transmute() basically combines the functionality of mutate() and select(). You can both define the columns you want to keep and mutate others. bond %&gt;% transmute(actor,filmname,gross=gross*1000000) I personally like transmute() for selecting columns. However, select() and mutate() are appropriate in some situations. 6.6 How to Filter a Data Frame with dplyr in R To filter rows in a data frame, use the filter() function: bond %&gt;% filter(year&gt;=1980 &amp; actor==&quot;Daniel Craig&quot;) If you noticed, we used the same operators as in base R. We can use any R operators as below: Table 6.1: R Operators label symbol less than &lt; greater than &gt; less than or equal &lt;= greater than or equal &gt;= equal == does not equal != and &amp; or | in %in% You can apply any of these operators the filter() function: bond %&gt;% filter(actor == &quot;Daniel Craig&quot; | actor == &quot;Sean Connery&quot;) bond %&gt;% filter(gross &gt;= 700 &amp; year &lt; 2000) Like in base R, you can also pass vectors in for dynamic filters: actor_list &lt;- c(&quot;Daniel Craig&quot;,&quot;Sean Connery&quot;,&quot;Timothy Dalton&quot;) bond %&gt;% filter(actor %in% actor_list) 6.7 How to Summarize and Group Data with dplyr in R Probably the most useful thing about dplyr is the ability to create new data frames that group and summarize data found in the larger data set. This is the primary reason I like dplyr. Let’s say you wanted to take the Bond data set and find out the gross revenue mean and standard deviation for Daniel Craig and Sean Connery. To accomplish this in base R, you’d have to use the following code: data.frame(actor_subselect=c(&quot;Daniel Craig&quot;,&quot;Sean Connery&quot;), average_revenue=c(mean(bond[bond$actor==&quot;Daniel Craig&quot;,&quot;gross&quot;]), mean(bond[bond$actor==&quot;Sean Connery&quot;,&quot;gross&quot;])), sdev_revenue=c(sd(bond[bond$actor==&quot;Daniel Craig&quot;,&quot;gross&quot;]), sd(bond[bond$actor==&quot;Sean Connery&quot;,&quot;gross&quot;]))) It’s not very simple, is it? Imagine having to do that for a much larger data set with even more actors! dplyr’s group_by() and summarize() functions really cut down on this work. Here’s how we can accomplish the same thing as above: bond %&gt;% filter(actor==&quot;Daniel Craig&quot; | actor == &quot;Sean Connery&quot;) %&gt;% group_by(actor) %&gt;% summarize(average_revenue=mean(gross),sdev_revenue=sd(gross)) Now you’ll notice this script isn’t shorter than what we did earlier. However, it’s a lot easier to read. That’s the beauty of dplyr! 6.8 Things to Remember dplyr is a package that provides a more intuitive syntax for transforming and analyzing data frames in R Select and create new columns with select(), mutate(), and transmute() Filter rows with filter() and the base R operators Provide summary statistics with group_by() and summarize() functions "],["packages.html", "Chapter 7 Understanding and Using R Packages 7.1 Why Does R Use Packages? 7.2 How to Access R Packages 7.3 How to Install and Load a Package - The Easy Way 7.4 Why You Should Still Learn to Install and Load Packages the “Old Fashioned” Way 7.5 How to Install and Load R Packages - The Old Fashioned Way 7.6 A Simple Trick to Include Install and Load Any Packages Needed 7.7 How to Find New Packages to Install 7.8 How to Find Documentation on Packages 7.9 Things to Remember", " Chapter 7 Understanding and Using R Packages Packages are one of the most important concepts in R programming. It’s almost hard to conceive R programming without them. An R package stores various functions and data sets for other users to access. It allows R to move beyond its roots in statistical programming and achieve more complex goals. For example, you might be writing a research paper. You want to clearly show the results of your regression analysis in this report, along with various tables and charts. You can use a combination of Rmarkdown, ggplot2, xtable, and various other packages to accomplish this goal. That way you don’t have to copy and paste your work to a word document as you analyze the results. You merely write it and program it in R and then export it to Word when you’re done. This saves you a lot of time in the long run and makes your code far more re-producible. 7.1 Why Does R Use Packages? Packages allow R to operate as an open source language. Programmers, statisticians, and data scientists can develop new functions and commands and then share them with other users elsewhere - for free! This is common for open source programming languages. If you want, you can actually develop you’re own package. If you find existing resources don’t perform or operate the way you’d like, you can develop your own functions and save them in a package for others to use. 7.2 How to Access R Packages Before I show you how to use an R package, you need to understand there’s a difference between installing and loading a package. Installing means pulling it from CRAN and saving it on your computer. Loading a package means using it in your current R session. Why would R do this? Mostly for efficiency. It would take more memory if your R session ran every package installed on your computer. It improves your computer’s performance to load packages only as you need them. Also, it’s not uncommon for R packages from different developers to have functions with the same name, but different purposes and inputs. Forcing you to load only the package with the function solves this issue. 7.3 How to Install and Load a Package - The Easy Way There are a couple of different ways to install and load packages. It depends on whether you need to save and re-use your code later or if you’re running a quick analysis. The easiest way to manage R packages is through RStudio’s user interface. This is better for quick analysis that you don’t need to save. The RStudio packages tab on the bottom right pane neatly organizes and details your current packages: You can use this tab to install and download a package. To install a package, select the install button: After that, type in the name of your package. In the example below, I type in “dplyr” to install the dplyr package. You will now see this package show up in the packages tab in the bottom right pane of RStudio: This doesn’t make the dplyr package available for us to use though. We still have to load it. This is where RStudio makes things easy. All you have to do is click the little check box next to dplyr to load it. And now your package is loaded! 7.4 Why You Should Still Learn to Install and Load Packages the “Old Fashioned” Way A developer once told me people who use RStudio weren’t real “programmers.” Real programmers, he said, type everything out by hand. RStudio was for “posers.” If that’s true, I am happy to be a poser. RStudio makes package management far easier. But there are some legitimate reasons to use the old fashioned methods, other than proving yourself as a real programmer. If you need to share your code with other people, for example, it’s better to include any code that installs and / or loads packages needed. That way the person opening your script doesn’t have to guess which packages to load. 7.5 How to Install and Load R Packages - The Old Fashioned Way There are two key functions you need to remember to install and load a package: 1. install.packages() 2. library() install.packages() installs the package from CRAN onto your computer. library() will load it into your current R session. Oddly enough, there’s a difference in notation between the two. The install.packages() function requires you to put quotations \"\" around the package name. library() does not. To see what I mean, look at the example down below: install.packages(&quot;dplyr&quot;) library(dplyr) Notice how the quotations marks are used in the first function? This is required for install.packages(). The library() function does not require it, but you can use quotation marks and it’ll still execute. 7.6 A Simple Trick to Include Install and Load Any Packages Needed If you share your R script with a colleague, they may not have all packages needed on their local computer to execute it. To take care of this, you can include both the install.packages() and library() functions at the top of the script. If it’s a script that only you’ll use in the future, you only need to include the library() function near the beginning, as you already installed the package beforehand. 7.7 How to Find New Packages to Install One of the best kept secrets of computer engineers and programmers is that the majority of what they learned came from Google. Every time something doesn’t work, they google how to do it. Changes are high that you’ll do the same as you program in R and most of these sites will tell you what packages to download. It’s typically in the top left or right corner. For example, I recently google’d “survival analysis in R.” Unlike regression analysis, R doesn’t have handy base functions to perform survival analysis. I found a couple of websites with information on how to do this in R. All of them required a new package called survival, which they displayed in the top left or right of the website. 7.8 How to Find Documentation on Packages Most packages you install will have documentation with it. Sadly, much of this documentation is unreadable, but it’s still a great resource and I rely on it heavily. To access this documentation, you can click on the hyperlinked package name in the packages tab. Click on the dplyr link on your own RStudio screen to see what I mean: This will take you to the Help tab and you can see documentation on all commands, functions, and data sets for a given package. You can select any of these hyperlinks to view instructions for how to use a specific function from this package. Down below, I select the mutate function documentation. And this will take you to the documentation page. As you may have noticed, the documentation also lists the function’s package in the top left hand of the corner. This is useful as you look up functions later. You can also use certain commands to pull up this documentation. The following will bring up a package’s documentation in the Help tab. ?dplyr() And you can look up individual functions from the package. ?mutate() 7.9 Things to Remember Packages are what allows you to adapt R programming to meet your needs You can install and load packages using the Packages tab in RStudio or the install.packages() and library() commands Whenever you research new functions on the internet, you will often see the package required in the top left or right hand corner You can research packages using the Help tab in RStudio "],["functions.html", "Chapter 8 Functions 8.1 Two Approaches to Using R Functions 8.2 Why You Should Learn to Write Your Own Functions 8.3 The Components of an R Function 8.4 Required versus Non-Required Arguments 8.5 When Order Matters for Arguments 8.6 How to Write Your Own Function 8.7 Writing Functions Using Control Flows 8.8 Applying a Control Flow to Our Summary Stats Function 8.9 Breaking Down the Function We Just Made 8.10 Things to Remember 8.11 Exercises", " Chapter 8 Functions As I said a few chapters ago, R programming runs on objects. Most object types relate to the way data is stored and how it’s handled. There’s one object type, though, that’s unique compared to the others. That would be the function object type. R functions allow you to script out various commands to transform and analyze data. This can be as simple as taking data from a vector and outputting a data frame. Or it could be something as complicated as a machine learning algorithm! It all depends on your own R programming goals. 8.1 Two Approaches to Using R Functions There’s two approaches that you can take with functions: use an existing function write your own function Both methods use the same underlying structure. The more common functions you’ll use include those in the R base and stats packages. These automatically come with R. These functions perform common calculations needed for statistical programming, such as mean(), sum(), sd(), lm(), glm() and confint(). Other “existing” functions can include those developed by other R programmers, which you can access by installing and loading other packages. (See the chapter on R packages for more details) 8.2 Why You Should Learn to Write Your Own Functions R is flexible enough though that you can write your own functions as well. This might sound like more trouble than it’s worth, but it’s really not. It takes a lot of time to learn other people’s functions. Not only that, you have to verify that their functions perform accurately. That’s especially true for packages developed by lesser known organizations. Sadly, not every package out there goes through rigorous quality checks and much of the documentation is poorly written. So it’s easy to misunderstand how a function works and then use it incorrectly. As a matter of fact, my professor in my machine learning class suggested creating our own scripts for some more advanced machine learning processes because existing packages didn’t work in every context. This is the trade off with open source programming languages. 8.3 The Components of an R Function Regardless of whether you use an existing function or write your own, both require the same components to execute: argument and a value. These are the technical terms for it, but it might be easier to think of an argument as the input and the value as the output. Fortunately, R documentation tells you what the required arguments are for existing functions. Simply add a question mark ? before a function and the documentation will appear in the Help tab on the bottom right pane of RStudio. Try it yourself with these functions: ?mean ?sd ?cor ?confint In the example of the mean function, we see that it requires at least an x value. The Arguments section of the documentation states that x is merely an R object. We can see the Value section gives details on the output this function will generate. 8.4 Required versus Non-Required Arguments You may have noticed in the documentation for the mean() function that there were two other arguments: trim and na.rm. The mean() function still can execute, even if you don’t specify what those arguments are. The reason is that there’s a default setting already in place for them. Whoever created this function set the default for the trim to 0 and the na.rm argument to FALSE. That way the user only has to modify those arguments if it’s necessary. 8.5 When Order Matters for Arguments If you execute ?lm in your console, you’ll see the linear model function has argument options for formula, data, subset, weights, etc. That means we could execute the model using our Bond data as lm(gross~actor,bond). Even though we don’t specify the arguments, R will execute this function because the formula argument (gross~actor) and the data argument (bond) are placed in the correct order. You can see this order in the documentation: If we tried this backwards, it wouldn’t work. Executing lm(bond,gross~actor) in your console would throw up an error. However, if we specify the arguments with an equal = sign, it will execute. That would look like this: lm(data=bond,formula=gross~actor). 8.6 How to Write Your Own Function As you may have noticed, existing R functions require at least one argument (with the option for more) and typically displays at least one values as an output. If you write your own functions, they’ll need the same thing. According to R’s own base documentation, a function is defined by an assignment, such as: name &lt;- function(arg_1, arg_2, …) expression We’re going to follow this convention and create several functions, with each one becoming more and more complex. Our end goal will be to create a function that: takes a data set groups data based on a single categorical variable calculates the mean and standard deviation of a continuous variable But we’ll start with a simpler version of this first. Before we begin though, go ahead and reload James Bond data set, as we’ll use it in our examples later. bond &lt;- read.csv(&quot;https://raw.githubusercontent.com/taylorrodgers/bond/main/bond.csv&quot;) Our first function will calculate standard deviation for a continuous variable. This function actually exists already (?sd), but we want to become familiar with something simple before moving on to something that’s more complicated. First, we’ll need a name for the function and any arguments we know will need to be passed through. We know it’ll require a data frame and a field to calculate standard deviation. I call those data and field, respectively. I name the function sd.simple. You can see in the script below the template for a function and the new name and arguments that I replaced it with. # Template name &lt;- function(arg_1, arg_2, …) expression # New function sd.simple &lt;- function(data, field) expression Now we’ll need to calculate add an expression. An expression is the actual script that takes your arguments and uses them to execute certain tasks. Our expression will need to use the data frame, grouping variable, and calculate standard deviation. To start the expression part of a new function, we use the {} notations: sd.simple &lt;- function(data, field) { } Next, we need the function to evaluate the data frame that’s placed in the data argument and select the field that’s specified. To do this, we use the same methods we used for selecting data from a data frame. (Note: when you design functions, it’s important to keep in mind the type of objects that will be entered into a function.) Now if we’re selecting a field directly from the Bond data frame we created earlier, our script would look something like this: bond[,&quot;gross&quot;] Since I want this function to be able to evaluate any data frame and field inputted, I simply replace certain parts of the script with the arguments. That means I replace “bond” with “data” and “gross” with “field,” which were the arguments I specified when I started writing this function. See what I mean below: sd.simple &lt;- function(data,field) { field &lt;- data[,paste(field)] } Now you probably realized that I actually replaced “gross” with paste(field). The paste() function is a handy little tool when it comes to writing your own R functions. It allows you to inject an argument into a filtering command. So when we later specify our field argument to be “gross”, it’ll simply plug that argument into the function to filter the data frame. It probably confused you why we’re assigning an object the name field when we’ve already specified that as an argument. This will be more clear later, but it’s because the field argument is used to specify a variable within a data frame - not an existing R object. To make it easier to analyze in our next part of the function, we need to turn it into it’s own object. Next, we need to write a script to calculate standard devation. We’ll use the sample standard deviation equation, which is: \\[ \\sqrt{\\frac{\\sum{(X_i-\\bar{X})^2}}{n-1}} \\] And we’ll plug that into our function: sd.simple &lt;- function(data,field) { field &lt;- data[,paste(field)] sqrt(sum((field - mean(field))^2) / (length(field) - 1)) } And walla! We created our first function! To execute this function, we simply plug our arguments into the function. sd.simple(bond,&quot;gross&quot;) ## [1] 214.4881 If you notice, I put quotation marks around the field argument “gross”. That’s because that argument is used with filtering a data frame, which requires quotation marks when we filter down to a column by column name (i.e. data.frame[,\"column name\"]). If we were using column number, we wouldn’t need to use a quotation mark (i.e. data.frame[,n]). We can check our work against the existing sd() function already built into R to make sure we did it correctly. sd.simple(bond,&quot;gross&quot;) == sd(bond[,&quot;gross&quot;]) ## [1] TRUE Looks like we got it right! 8.7 Writing Functions Using Control Flows The truth is that you typically won’t need to write short functions like this one because there’s plenty of existing functions in base R that perform these kinds of calculations. The functions you’ll need to write are able to evaluate large amounts of data and run calculations on subsets of said data. That’s where things get tricky and where function writing is both a benefit and challenge. That’s where the control flow comes in handy. Some people call them “loops,” which I think is an easier term myself. A control flow simply repeats a calculation over and over again for certain subgroups. Even though this is easy to conceive, it’s a challenge to implement it without lots of thought and planning. There’s several different types of control flows, which you can read up by executing ?Control in your console. The one we’ll use is the for (var in seq) expr version. It’s hard to visualize how that works, unless we provide an example. Down below I create a loop that prints each individual word in the statement vector until we reach the end. statement &lt;- c(&quot;This&quot;,&quot;book&quot;,&quot;is&quot;,&quot;the&quot;,&quot;greatest&quot;, &quot;book&quot;,&quot;ever&quot;,&quot;and&quot;,&quot;I&quot;,&quot;will&quot;, &quot;recommend&quot;,&quot;it&quot;,&quot;to&quot;,&quot;everyone&quot;) for (i in 1:length(statement)) { print(statement[i]) } ## [1] &quot;This&quot; ## [1] &quot;book&quot; ## [1] &quot;is&quot; ## [1] &quot;the&quot; ## [1] &quot;greatest&quot; ## [1] &quot;book&quot; ## [1] &quot;ever&quot; ## [1] &quot;and&quot; ## [1] &quot;I&quot; ## [1] &quot;will&quot; ## [1] &quot;recommend&quot; ## [1] &quot;it&quot; ## [1] &quot;to&quot; ## [1] &quot;everyone&quot; First, I create the vector. Then I said print every i entry of the vector until we reach the end. Even though this is a simple example, you can see why this would be useful in larger, more complicated scripting. 8.8 Applying a Control Flow to Our Summary Stats Function Now we’re going to build upon our previous function with a control flow and use it to report both standard deviation and the average of a subgroup within a larger data frame. We’ll demonstrate this using the Bond data frame and report those summary statistics for each Bond actor’s net gross. First, to make sure it’s easy to visualize what we’re doing, I’m going to replace our own standard deviation script with the built-in sd() function. I’m also going to add the built-in mean() function and rename the function to “summary.group”. summary.group &lt;- function(data,field) { field &lt;- data[,paste(field)] sd(field) mean(field) } Next, I’m going to replace the field assignment with groups and output. summary.group &lt;- function(data, group, field) { groups &lt;- levels(factor(data[,paste(group)])) output &lt;- data.frame(group=character(), mean=numeric(), sd=numeric()) sd(field) mean(field) } The groups object creates a short vector that specifies the groups we want to evaluate. Since we’ll evaluate the actors in the Bond data frame, this would be Daniel Craig, Sean Connery, etc. It works similarly to the previous field object assignment we had. The output object is an empty data frame that will populate with our summary statistics, such as mean and standard deviation, as the control flow evaluates each subgroup. We want to create an empty data frame before the control flow, otherwise the control flow will continuously overwrite itself. Now we’ll begin our control flow. Down below I add the control flow and it evaluates each individual group found at the beginning of the function: summary.group &lt;- function(data,group,field) { groups &lt;- levels(factor(data[,paste(group)])) output &lt;- data.frame(group=character(), mean=numeric(), sd=numeric()) for(i in 1:length(groups)) { #sd(field) - can&#39;t run properly yet #mean(field) - can&#39;t run properly yet } } Now we’ll want to update the output data frame with the group name, the mean, and the standard deviation: summary.group &lt;- function(data,group,field) { groups &lt;- levels(factor(data[,paste(group)])) output &lt;- data.frame(group=character(), mean=numeric(), sd=numeric()) for(i in 1:length(groups)) { subdata &lt;- data[data[,paste(group)]==groups[i], paste(field)] output[i,1:3] &lt;- data.frame(groups[i], mean(subdata), sd(subdata)) } } Now there was a lot added there and I should explain. The subdata object filters down the data to the group we want to evaluate. The output[i,1:3] object updates the output data frame for row i with the group name, the mean of the field within that group, and the standard deviation. Now this function will run, but there’s still one piece we’re missing. We need to provide a value. In this function, our value we want to use is the output object, which is the data frame containing our summary statistics. We can merely add the output reference at the end, outside the control flow: summary.group &lt;- function(data,group,field) { groups &lt;- levels(factor(data[,paste(group)])) output &lt;- data.frame(group=character(), mean=numeric(), sd=numeric()) for(i in 1:length(groups)) { subdata &lt;- data[data[,paste(group)]==groups[i], paste(field)] output[i,1:3] &lt;- data.frame(groups[i], mean(subdata), sd(subdata)) } output } If we run this function with the Bond data frame, we’ll get this result: summary.group(bond,&quot;actor&quot;,&quot;gross&quot;) ## group mean sd ## 1 Daniel Craig 820.3165 222.57396 ## 2 George Lazenby 505.8998 &lt;NA&gt; ## 3 Pierce Brosnan 510.938 30.61869 ## 4 Roger Moore 550.8332 177.6345 ## 5 Sean Connery 724.8824 213.95672 ## 6 Timothy Dalton 333.123 67.83394 8.9 Breaking Down the Function We Just Made This probably is confusing to you since you’re not totally familiar with R control flows yet. It also doesn’t help that you’re still learning how to filter and transform the various object types. To make it easier, I’m going to show you step-by-step how this function took the Bond data and created this output. First, the function reviewed the group we defined and created a vector with the members of that group. In this instance, that would include the Bond actors: levels(factor(bond[,&quot;actor&quot;])) ## [1] &quot;Daniel Craig&quot; &quot;George Lazenby&quot; &quot;Pierce Brosnan&quot; &quot;Roger Moore&quot; ## [5] &quot;Sean Connery&quot; &quot;Timothy Dalton&quot; Second, the function created an empty data frame that will later store the actor names, their mean, and their standard deviation: Our function then started a control flow, which will evaluate each actor’s data to fill the data frame we just created: Next, it filtered the Bond data set down to the first actor: Really, this function filtered the Bond data set in a similar way to the code below: groups &lt;- levels(factor(bond[,&quot;actor&quot;])) bond[bond[,&quot;actor&quot;]==groups[1],&quot;gross&quot;] ## [1] 1108.5610 880.6692 669.7895 622.2464 The function then took the subdata and calculated our summary statistics. This populated the empty data set one by one… …with each new row looked something like this: ## groups.1. mean.subdata. sd.subdata. ## 1 Daniel Craig 820.3165 222.574 And finally, it displayed the complete data frame once finished with the control flow! ## Assigning Functions Outputs a Name Any objects named within a function are not saved in your R environment. To save the results, you need to assign the executed function a name, like you would with any other object. bond_eval &lt;- summary.group(bond,&quot;actor&quot;,&quot;gross&quot;) bond_eval This can apply to any existing functions. 8.10 Things to Remember Functions are the only object type that modifies other objects Functions require an argument to execute and typically outputs a value Packages store various previously built functions that you can utilize You can build your own functions to suit your R programming needs Control flows or “loops” are a handy way to automate data management tasks at a granular level 8.11 Exercises Try to see if you can complete the following exercises. Answers are in the back of the book! Modify the simply standard deviation function we wrote and change it to calculate mean. Do this without using the built-in mean function. Alter the summary.group function to include median, maximum, and minimum values. Write a function for the Fibonacci Sequence, which ends at a number you choose. You’ll need to use a control flow to accomplish this and a default value for the end of the sequence. (Hint: You won’t use the for(var in seq) expr control flow. Execute ?Control to use a different version.) "],["importdata.html", "Chapter 9 Importing Data into R 9.1 How to Import a Raw Data File the Easy Way 9.2 Import a Raw Data File the Hard Way 9.3 Save Import Functions 9.4 Connect to a Database 9.5 Connect to an API 9.6 Why API Connections Are Sometimes Overrated 9.7 Things to Remember", " Chapter 9 Importing Data into R There’s three good ways to import data into R: Import a raw data file (.csv, .xlsx, .tsv, etc.) Connect to a database (SQL Server, AWS, etc.) Connect to an API (Google Analytics, Census Bureau, etc.) Students and researchers will use the first option the most. That’s because your data sets are usually smaller and don’t require a database. You can both write a command or use the RStudio user interface to import raw data files. The second option is what you’ll use while working for a large organization. Most data is stored in a large database that you can access. If you work with a SQL database, you’re in luck. You can access your database directly with RStudio! Although it does require some setup. The third option involves connecting to an application programming interface (API). That’s a fancy way of saying you connect to an online application. Typically, you’ll download existing packages that make this easier. That’s not always true though. Sometimes you’ll be stuck writing your own code to access an API and you may wonder if it’s simply better to download the raw data files to import. 9.1 How to Import a Raw Data File the Easy Way RStudio makes routine steps like raw data import easy. In the top right pane, you’ll see an Import Dataset button. Click that. You should get a menu that looks like this: For the following example, we’ll select “From Text (readr)…”. This allows us to import .csv, .txt, and other text files. Importing a SAS data file isn’t all that different from importing a CSV file. Click on “From Text(readr)…” and you should see this screen: To get started, we first need to provide a file path or a URL in the top search bar. (Just use any raw data file on your computer or go to Kaggle.com to find one.) You can select “Browse…” to find a specific file on your computer. Down below, you’ll see I selected a .tsv file. As you can see, the data doesn’t look right. That’s because the RStudio’s default setting for raw data import assumes the data is comma-delimited. We need to change the Delimator: option to “Tab.” The data should look like this now: Before you hit Import in the bottom right-hand corner of the window, look at what RStudio produced in the box above it. As you can see, RStudio writes the script you’ll use to import this data set. Selecting “import” will run this script afterwards. Go ahead and hit import now. You’ll then see your data set appear as a data frame in the environment tab: Congrats! You successfully imported a raw data file. You can follow similar steps for Excel, SAS, STATA, and other data file types! 9.2 Import a Raw Data File the Hard Way In the last section, I actually provided a clue on how to import raw data the “hard” way. If you remember, I showed how using RStudio’s built-in Import Dataset option will write the script that R will use to execute and import data: The hard way is writing that code yourself. Personally, I think that’s a waste of time. I could see how some people might do it to show off how good at R programming they are, but I don’t seek such recognition. I say just let the RStudio UI do it. 9.3 Save Import Functions It is a good idea, however, to save the scripts RStudio generates whenever you need to save a document. For example, you may have a raw data set saved to a URL or a shared drive in your organization. You may also need to share your R script as a saved file with other people. In that case, you want to go ahead and save the scripts to import all relevant data. You’ll need to include that at the top of your document, so future programmers can execute it and use the same data sets in your analysis. Here’s an example of how you’ll do that: library(readr) summer_train &lt;- read_delim(&quot;Downloads/summer_train.tsv&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) summer_test &lt;- read_delim(&quot;Downloads/summer_test.tsv&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) customers_data &lt;- read_csv(&quot;Downloads/Wholesale customers data.csv&quot;) library(haven) kidney &lt;- read_sas(&quot;Downloads/kidney.sas7bdat&quot;, NULL) In the script above, I also made sure to load both the readr and haven package. Both are required to load the file paths below them. 9.4 Connect to a Database To connect to a database tool, work with your RStudio admin. Ask them for key connection information, such as: Driver Server URL or IP address Database name User name and password (if different from your typical username and password) Port Typically, these are the same inputs used when signing into your organization’s database management software. You’ll also need to ensure there’s a driver setup on your local computer or on the network you use. I would ask that your RStudio admin to do this for you. Once they have created the driver and you have the necessary credentials, you can connect to the database in the Connections tab in the upper-right pane: Once you run through this process, you’ll often see the menu option generate a script that looks similar to this: library(odbc) con &lt;- dbConnect(odbc(), Driver = &quot;SQLServer&quot;, Server = &quot;sqlhostname&quot;, Database = &quot;dbase&quot;, UID = &quot;username&quot;, PWD = rstudioapi::askForPassword(&quot;Database password:&quot;), Port = 1433) You can then use the dbReadTable() function in the DBI package to import a table from the database into an R data frame: dataset &lt;- dbReadTable(con,&quot;tablename&quot;) If you intend to share your work, I would include these connections at the top of your R script. 9.5 Connect to an API Much like database, API connections are very tool specific. Actually, I’d say they’re more tool specific than database connections. You’ll need to configure both the source tool and R to accomplish this. Fortunately, there are R packages for the most common API connections out there. I would search something like “R package for tool-name API connection.” You’ll often find what you need. If you want to get practice with an API connection, you can read my article about connecting to the US Census Bureau’s API at www.taylorrodgers.com. 9.6 Why API Connections Are Sometimes Overrated I think API connections are a bit overrated – at least when it comes to R programming. The reason relates to R’s strengths and weaknesses. In my professional experience, API connections are handy for ETL processes. Typically, you need to automate ETL processes. Not only for data science, but also general data reporting and application support. That means API connections often require a production environment – something R programming struggles with. One common example relates to Google Analytics. I’ve worked with a few marketing firms and it’s not uncommon for agencies to manage multiple websites. Even if you analyze that data as a data scientist, it’s more efficient to build a database first that houses all that data in a centralized, standardized location. R can connect to the Google Analytics API and analyze data, but it can’t build production quality scripts that automate that process. Therefore, it’d be better to connect to the database that already aggregated the Google Analytics data for you. Now this doesn’t mean API connections via R are useless. There are examples I’ve found that are more common to researchers. One example where I think connecting to an API makes sense is accessing public databases to conduct one-time analyses. A programmer spoke at my local R User Group about assisting his wife, who was an academic researcher, pull global news data from a public database online. It made sense in that context to connect to the API via R because you wouldn’t have a use for that data again in the near future. Another example would be connecting to the US Census Bureau’s API. I wrote a blog post on that some time ago. Downloading that raw data files from the US Census Bureau is a pain and the API, while also a bit overwhelming, still saves a lot of time. I don’t see a scenario where it makes sense for an organization to automate data collection from the US Census Bureau, because that data isn’t updated that often. 9.7 Things to Remember Import raw data through the Import Dataset button in the Environment tab in the upper-right pane Connect to databases through the Connections tab in the upper-right pane Work with your data engineering or IT team for setting up the necessary drivers and credentials for database connections API connections are handy for large, one time analysis Download specific packages to connect to an API "],["answers.html", "Chapter 10 Answer Key 10.1 Chapter 3 10.2 Chapter 5", " Chapter 10 Answer Key 10.1 Chapter 3 Filter the following vector to values greater than 2 q1 &lt;- seq(1,20,2) q1[q1 &gt; 2] Filter the following vector to values between 20 and 30, but only for the first three entries that meet that criteria. (Hint: add [n:n] for the range of values after you determine which values meet that criteria) q2 &lt;- round(rnorm(20,32,7),0) q2 &gt;= 20 &amp; q2 &lt;= 30 q2[q2 &gt;= 20 &amp; q2 &lt;= 30][1:3] Multiple the following matrices together. q3_1 &lt;- matrix(round(seq(1,40,3.27),0),3) q3_2 &lt;- matrix(seq(1,8,1),4) q3_1 %*% q3_2 Subtract 41 from every entry in the second column of the following matrix. Replace the column with those new values. q4 &lt;- matrix(seq(1,120,4),10,3) q4 q4[,2] &lt;- q4[,2] - 41 q4 Select the second row each matrix in the following array. Subtract 5 from those rows. q5 &lt;- array(data=c(matrix(seq(1,15,1),5,3), matrix(seq(4,60,4),5,3), matrix(seq(2,30,2),5,3)), dim=c(5,3,3)) q5 q5[2,,]-5 Filter the following data frame to Bond films starring Roger Moore. bond[bond[&quot;actor&quot;]==&quot;Roger Moore&quot;,] Filter the following data frame to Bond films starring Sean Connery made after 1966. bond[bond[&quot;actor&quot;]==&quot;Sean Connery&quot; &amp; bond[&quot;year&quot;] &gt; 1966,] 10.2 Chapter 5 Modify the simply standard deviation function we wrote and change it to calculate mean. Do this without using the built-in mean function. avg.simple &lt;- function(data,field) { field &lt;- data[,paste(field)] sum(field)/length(field) } Alter the summary.group function to include median, minimum, and maximum values. summary.group &lt;- function(data,group,field) { groups &lt;- levels(factor(data[,paste(group)])) output &lt;- data.frame(group=character(), mean=numeric(), sd=numeric(), median=numeric(), minimum=numeric(), maximum=numeric()) for(i in 1:length(groups)) { subdata &lt;- data[data[,paste(group)]==groups[i], paste(field)] output[i,1:6] &lt;- data.frame(groups[i], mean(subdata), sd(subdata), median(subdata), min(subdata), max(subdata)) } output } Write a function for the Fibonacci Sequence, which ends at a number you choose. You’ll need to use a control flow to accomplish this and a default value for the end of the sequence. (Hint: You won’t use the for(var in seq) expr control flow. Execute ?Control to use a different version.) xn=xn-1 + xn-2 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55 fib &lt;- function(end=55){ x &lt;- c(0,1) n &lt;- length(x) while(x[n]&lt;end){ x[n+1] &lt;- x[n]+x[n-1] n &lt;- length(x) } x } "],["references.html", "References", " References "]]
